{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "345c3473",
   "metadata": {},
   "source": [
    "\n",
    "## CLASSIFICATION - AUTHENTIFICATION DES BILLETS DE BANQUE \n",
    "\n",
    "\n",
    "Notre tutoriel porte sur l'authentification de billets de banque. Pour cela nous allons utiliser le dataset suivant: https://www.kaggle.com/datasets/ritesaluja/bank-note-authentication-uci-data (disponible sur Kaggle).    \n",
    "\n",
    "Il permet de créer un modèle capable de détecter les billets de banque authentiques et faux. Ce jeu de données contient un certain nombre de mesures prises à partir d'images numérisées. Les images sont créées à l'aide d'une caméra industrielle qui est habituellement utilisée pour l'inspection des imprimés. Les images sont de 400x 400 pixels. \n",
    "\n",
    "Dans ce notebook nous allons nous concentrer sur un exemple de classification binaire, où le modèle doit prédire si un billet de banque est une contrefaçon ou pas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345398b0",
   "metadata": {},
   "source": [
    "## Exploration des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2325c01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variance  skewness  curtosis  entropy  class\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Télecharger au préalable le fichier à travers le lien, dans le même dossier que ce notebook.\n",
    "\n",
    "#Charger le fichier csv de données \n",
    "import pandas as pd\n",
    "Bank_data = pd.read_csv(\"BankNote_Authentication.csv\")\n",
    "Bank_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dfdf4d",
   "metadata": {},
   "source": [
    "## Description des données\n",
    "\n",
    "Ce jeu de données contient 5 colonnes: une étiquette \"class\" qui identifie le statut d'un billet de banque (0 pour faux et 1 pour vrai) et quatres caractéristiques. \n",
    "\n",
    "Les quatre caractéristiques ont été extraites des images de billets de banque:\n",
    "\n",
    "-\"Variance\": mesure l'étendue de la dispersion d'un ensemble de nombres.\n",
    "\n",
    "-\"Skewness\": mesure l'asymétrie de la distribution de probabilité d'une variable aléatoire à valeur réelle.\n",
    "\n",
    "-\"Curtosis\": mesure la forme de la distribution de probabilité d'une variable aléatoire à valeur réelle.\n",
    "\n",
    "-\"Entropy\": mesure la quantité d'information ou du caractère aléatoire, qui est représentée par la différence entre des pixels adjacents.\n",
    "\n",
    "Il s'agit d'un excellent jeu de données pour pratiquer la classification binaire.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d16f13",
   "metadata": {},
   "source": [
    "## Nettoyage des données\n",
    "\n",
    "Après avoir légèrement exploré nos données, nous pouvons passer au nettoyage de celles-ci. Le fait de disposer de données propres augmentera en fin de compte la productivité globale et permettra de disposer d'informations de la plus haute qualité pour entrainer le modèle.\n",
    "\n",
    "Les données incomplètes ou manquantes constituent l'un des problèmes les plus courants auxquels les spécialistes des données doivent faire face. Alors comment savoir si le DataFrame contient des valeurs manquantes ? On peut utiliser les fonctions isnull() et sum() pour identifier les valeurs qui sont nulles, comme ceci :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47ca2e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variance    0\n",
       "skewness    0\n",
       "curtosis    0\n",
       "entropy     0\n",
       "class       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bank_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cac0ca9",
   "metadata": {},
   "source": [
    "Aucune valeur nulle. Nous remarquons aussi que nous n'avons pas de problèmes de typage toutes les caractéristiques sont des décimaux relatifs et la classe un entier ce qui colle à la réalité. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ef4685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variance    float64\n",
       "skewness    float64\n",
       "curtosis    float64\n",
       "entropy     float64\n",
       "class         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bank_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c701ccb",
   "metadata": {},
   "source": [
    "Nous remarquons que les différentes caractéristiques ont des échelles différentes ce qui peut fausser les calculs. Une technique courante pour traiter des données numériques à différentes échelles consiste à normaliser les données afin que les valeurs conservent leur distribution proportionnelle, mais soient mesurées sur la même échelle. Pour ce faire, nous utiliserons une technique appelée mise à l'échelle MinMax qui distribue les valeurs proportionnellement sur une échelle de 0 à 1. Vous pourriez écrire le code pour appliquer cette transformation, mais la bibliothèque Scikit-Learn fournit un mesureur qui le fait pour vous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f224903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.769004</td>\n",
       "      <td>0.839643</td>\n",
       "      <td>0.106783</td>\n",
       "      <td>0.736628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.835659</td>\n",
       "      <td>0.820982</td>\n",
       "      <td>0.121804</td>\n",
       "      <td>0.644326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.786629</td>\n",
       "      <td>0.416648</td>\n",
       "      <td>0.310608</td>\n",
       "      <td>0.786951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.757105</td>\n",
       "      <td>0.871699</td>\n",
       "      <td>0.054921</td>\n",
       "      <td>0.450440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.531578</td>\n",
       "      <td>0.348662</td>\n",
       "      <td>0.424662</td>\n",
       "      <td>0.687362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.537124</td>\n",
       "      <td>0.565855</td>\n",
       "      <td>0.165249</td>\n",
       "      <td>0.726398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>0.407690</td>\n",
       "      <td>0.332868</td>\n",
       "      <td>0.506753</td>\n",
       "      <td>0.808350</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>0.237385</td>\n",
       "      <td>0.011768</td>\n",
       "      <td>0.985603</td>\n",
       "      <td>0.524755</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>0.250842</td>\n",
       "      <td>0.201701</td>\n",
       "      <td>0.761587</td>\n",
       "      <td>0.660675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>0.324528</td>\n",
       "      <td>0.490747</td>\n",
       "      <td>0.343348</td>\n",
       "      <td>0.885949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  curtosis   entropy  class\n",
       "0     0.769004  0.839643  0.106783  0.736628      0\n",
       "1     0.835659  0.820982  0.121804  0.644326      0\n",
       "2     0.786629  0.416648  0.310608  0.786951      0\n",
       "3     0.757105  0.871699  0.054921  0.450440      0\n",
       "4     0.531578  0.348662  0.424662  0.687362      0\n",
       "...        ...       ...       ...       ...    ...\n",
       "1367  0.537124  0.565855  0.165249  0.726398      1\n",
       "1368  0.407690  0.332868  0.506753  0.808350      1\n",
       "1369  0.237385  0.011768  0.985603  0.524755      1\n",
       "1370  0.250842  0.201701  0.761587  0.660675      1\n",
       "1371  0.324528  0.490747  0.343348  0.885949      1\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Obtenir un objet de mesure\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Créer un nouveau dataframe pour les valeurs mises à l'échelle.\n",
    "Bank_data_normalized = Bank_data[['variance', 'skewness', 'curtosis', 'entropy', 'class']].copy()\n",
    "\n",
    "# Normaliser les colonnes numériques\n",
    "Bank_data_normalized[['variance', 'skewness', 'curtosis', 'entropy']] = scaler.fit_transform(Bank_data_normalized[['variance', 'skewness', 'curtosis', 'entropy']])\n",
    "\n",
    "Bank_data_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09f72c0",
   "metadata": {},
   "source": [
    "## Séparer les étiquettes et les caractéristiques\n",
    "\n",
    "L'étiquette sera prédite par le modèle entrainé; les caractéristiques seront utilisées pour prédire le statut du billet. \n",
    "\n",
    "Il est nécéssaire de séparer au préalable les caractéristiques des étiquettes - nous appellerons les caractéristiques X et l'étiquette Y :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40c2a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on supprime class pour avoir les entrées(les caractéristiques).\n",
    "X = Bank_data_normalized.drop(columns=['class'])\n",
    "\n",
    "#on supprime les caractéristiques pour avoir la sortie(étiquette).\n",
    "y = Bank_data_normalized.drop(columns=['variance','skewness','curtosis','entropy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9f3e22",
   "metadata": {},
   "source": [
    "## Diviser les données\n",
    "\n",
    "Nous pouvons tirer parti du fait que nous disposons d'un grand ensemble de données avec des valeurs d'étiquettes connues, pour n'en utiliser qu'une partie pour entrainerle modèle, et en retenir une autre  pour tester le modèle formé - ce qui nous permet de comparer les étiquettes prédites avec les étiquettes déjà connues dans l'ensemble du test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b6c9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465f552e",
   "metadata": {},
   "source": [
    "## Former un modèle de classification binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "482bdfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création du modèle d'entrainement\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "#Entrainement du modèle\n",
    "model.fit(X_train.values, y_train)\n",
    "\n",
    "#Prédiction des données\n",
    "predictions = model.predict (X_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b1111f",
   "metadata": {},
   "source": [
    "## Evaluer le modèle\n",
    "\n",
    "Maintenant que nous avons formé le modèle à l'aide des données d'entrainement, nous pouvons utiliser les données de test que nous avons retenues pour évaluer la qualité de ses prédictions. La chose la plus évidente à faire est de vérifier la précision des prédictions - en termes simples, quelle proportion des étiquettes le modèle a-t-il prédit correctement ? Pour cela nous pouvons nous servir de l'accuracy score. Il s'agit d'une métrique permettant d'évaluer la performance des modèles de classification à 2 classes ou plus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d029b63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9854368932038835"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_test, predictions)\n",
    "score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8396dc2c",
   "metadata": {},
   "source": [
    "Maintenant que nous disposons d'un modèle entraîné raisonnablement utile, nous pouvons l'enregistrer pour l'utiliser ultérieurement afin de prédire les étiquettes de nouvelles données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08ecd054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bank-model.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " import joblib\n",
    "\n",
    "joblib.dump(model, 'Bank-model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b7b248",
   "metadata": {},
   "source": [
    "## Réutilisation du modèle\n",
    "\n",
    "Lorsque nous avons de nouvelles observations pour lesquelles l'étiquette est inconnue, nous pouvons charger le modèle et l'utiliser pour prédire les valeurs de l'étiquette inconnue :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fda97682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouvel élément: [2, 3, 4, 1]\n",
      "la classe prédite est 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Charger le modèle grâce au fichier sauvegardé\n",
    "model = joblib.load('Bank-model.joblib')\n",
    "\n",
    "#Nous allons créer un tableau avec un seul tableau de caractéristiques, représentant un billet.\n",
    "X_new = np.array([[2,3,4,1]])\n",
    "print ('Nouvel élément: {}'.format(list(X_new[0])))\n",
    "\n",
    "# Récupérer la prédiction\n",
    "pred = model.predict(X_new)\n",
    "\n",
    "# Le modèle renvoie un tableau de prédictions - une pour chaque ensemble de caractéristiques soumises.\n",
    "# Dans notre cas, nous n'avons soumis qu'un seul élément, donc notre prédiction est la première dans le tableau résultant.\n",
    "print('la classe prédite est {}'.format(pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d258d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
